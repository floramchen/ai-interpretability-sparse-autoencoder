{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4787b629",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58b20a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florachen/Documents/battery-brain-assets/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Running on macbook M2\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c1dd2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train[:1%]\")  # tiny subset\n",
    "texts = dataset[\"text\"][:5000]  # limit for speed\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c2d7062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 Loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load  GPT-2 small (124M)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2Model.from_pretrained(\"gpt2\", output_hidden_states=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"GPT-2 Loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "007b8393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 768)\n",
       "  (wpe): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-11): 12 x GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D(nf=2304, nx=768)\n",
       "        (c_proj): Conv1D(nf=768, nx=768)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D(nf=3072, nx=768)\n",
       "        (c_proj): Conv1D(nf=768, nx=3072)\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd93571d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Block(\n",
       "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (attn): GPT2Attention(\n",
       "    (c_attn): Conv1D(nf=2304, nx=768)\n",
       "    (c_proj): Conv1D(nf=768, nx=768)\n",
       "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (mlp): GPT2MLP(\n",
       "    (c_fc): Conv1D(nf=3072, nx=768)\n",
       "    (c_proj): Conv1D(nf=768, nx=3072)\n",
       "    (act): NewGELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.h[LAYER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49c4bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a mid-layer where polysemantic neurons are common\n",
    "LAYER = 6 \n",
    "\n",
    "# Hook layer to capture activations\n",
    "mlp_acts = []\n",
    "\n",
    "def hook_fn(module, inp, out):\n",
    "    # out is (batch, seq, hidden)\n",
    "    mlp_acts.append(out.detach().cpu())\n",
    "\n",
    "# GPT-2 MLP is in model.h[layer].mlp.c_fc\n",
    "layer_mlp = model.h[LAYER].mlp.c_fc\n",
    "hook = layer_mlp.register_forward_hook(hook_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3514d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:46<00:00, 46.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([636269, 3072])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect activations over dataset\n",
    "all_acts = []\n",
    "\n",
    "for text in tqdm(texts):\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128).to(device)\n",
    "    mlp_acts.clear()\n",
    "    with torch.no_grad():\n",
    "        _ = model(**tokens)\n",
    "    if len(mlp_acts) > 0:\n",
    "        acts = mlp_acts[0].squeeze(0)  # (seq, hidden)\n",
    "        all_acts.append(acts)\n",
    "\n",
    "all_acts = torch.cat(all_acts, dim=0)  # shape (N, d_hidden)\n",
    "all_acts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3091b420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072, 3072)\n"
     ]
    }
   ],
   "source": [
    "# 7. Detect polysemantic neurons\n",
    "#    Method: cluster activation patterns and see if \n",
    "#    neuron responds to multiple distinct contexts.\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "hidden_size = all_acts.shape[-1]\n",
    "\n",
    "# compute top-k activating tokens for each neuron\n",
    "k = 200\n",
    "top_examples = torch.topk(all_acts, k=k, dim=0).indices  # shape (k, hidden)\n",
    "\n",
    "# Represent each neuron by the contexts of its top activations\n",
    "neuron_vectors = []\n",
    "\n",
    "for neuron in range(hidden_size):\n",
    "    idxs = top_examples[:, neuron]\n",
    "    context_mats = all_acts[idxs]  # (k, hidden)\n",
    "    neuron_vectors.append(context_mats.mean(dim=0).numpy())\n",
    "\n",
    "neuron_vectors = np.stack(neuron_vectors)\n",
    "print(neuron_vectors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b80128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated polysemantic neurons: 115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[14,\n",
       " 31,\n",
       " 72,\n",
       " 87,\n",
       " 96,\n",
       " 136,\n",
       " 140,\n",
       " 162,\n",
       " 178,\n",
       " 227,\n",
       " 252,\n",
       " 257,\n",
       " 294,\n",
       " 310,\n",
       " 332,\n",
       " 341,\n",
       " 368,\n",
       " 375,\n",
       " 389,\n",
       " 442]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. KMeans to find neurons with multi-cluster activation patterns\n",
    "polysemantic_neurons = []\n",
    "\n",
    "for neuron in range(hidden_size):\n",
    "    activations = all_acts[top_examples[:, neuron], neuron].reshape(-1, 1)\n",
    "    kmeans = KMeans(n_clusters=2, n_init=5).fit(activations)\n",
    "    if kmeans.cluster_centers_[0][0] * kmeans.cluster_centers_[1][0] < 0.8 * max(kmeans.cluster_centers_):\n",
    "        polysemantic_neurons.append(neuron)\n",
    "\n",
    "print(\"Estimated polysemantic neurons:\", len(polysemantic_neurons))\n",
    "polysemantic_neurons[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bd35127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Build an Anthropic-Style Sparse Autoencoder (SAE)\n",
    "class AnthropicSAE(nn.Module):\n",
    "    def __init__(self, d_in, d_hidden):\n",
    "        super().__init__()\n",
    "        # No biases, small init\n",
    "        self.W_enc = nn.Parameter(torch.randn(d_hidden, d_in) * 0.02)\n",
    "        self.W_dec = nn.Parameter(torch.randn(d_in, d_hidden) * 0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Normalize decoder weights column-wise\n",
    "        W_dec_norm = self.W_dec / (self.W_dec.norm(dim=0, keepdim=True) + 1e-6)\n",
    "\n",
    "        # Encoder → ReLU sparse code\n",
    "        z = torch.relu(x @ self.W_enc.t())  # shape: [batch, d_hidden]\n",
    "\n",
    "        # Decoder reconstruction\n",
    "        x_hat = z @ W_dec_norm.t()\n",
    "\n",
    "        return x_hat, z\n",
    "\n",
    "\n",
    "# Instantiate SAE\n",
    "sae = AnthropicSAE(hidden_size, d_hidden=all_acts.shape[-1]*4).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6aaec0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Stable optimizer + LR\n",
    "opt = torch.optim.AdamW(sae.parameters(), lr=3e-4, weight_decay=0.0)\n",
    "\n",
    "# Normalize activations before training (VERY IMPORTANT)\n",
    "acts_mean = all_acts.mean(dim=0, keepdim=True)\n",
    "acts_std = all_acts.std(dim=0, keepdim=True) + 1e-6\n",
    "\n",
    "acts_normed = (all_acts - acts_mean) / acts_std\n",
    "acts_train = acts_normed.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53fbc747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1243/1243 [01:15<00:00, 16.46it/s]\n",
      "Epoch:  33%|███▎      | 1/3 [01:21<02:42, 81.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: MSE=0.0717, Sparsity=0.7247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1243/1243 [01:04<00:00, 19.16it/s]\n",
      "Epoch:  67%|██████▋   | 2/3 [02:26<01:11, 71.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: MSE=0.0100, Sparsity=0.9740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 1243/1243 [01:05<00:00, 19.04it/s]\n",
      "Epoch: 100%|██████████| 3/3 [03:31<00:00, 70.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: MSE=0.0069, Sparsity=1.0572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 10. Train SAE\n",
    "BATCH = 512\n",
    "EPOCHS = 3\n",
    "L1 = 1e-5\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS), desc=\"Epoch\"):\n",
    "    perm = torch.randperm(acts_train.shape[0])\n",
    "    acts_train = acts_train[perm]\n",
    "\n",
    "    running_mse = 0\n",
    "    running_l1 = 0\n",
    "    steps = 0\n",
    "\n",
    "    for i in tqdm(range(0, len(acts_train), BATCH), desc=\"Batch\"):\n",
    "        batch = acts_train[i:i+BATCH]\n",
    "        opt.zero_grad()\n",
    "\n",
    "        recon, z = sae(batch)\n",
    "\n",
    "        mse = ((recon - batch)**2).mean()\n",
    "        sparsity = z.abs().mean()\n",
    "\n",
    "        loss = mse + L1 * sparsity\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running_mse += mse.item()\n",
    "        running_l1 += sparsity.item()\n",
    "        steps += 1\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: MSE={running_mse/steps:.4f}, Sparsity={running_l1/steps:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "896fd212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BEFORE (polysemantic neuron) ===\n",
      "- Once upon a time there was a mommy, a daddy and a baby. Every day, Mommy and Daddy would take Baby t\n",
      "- Once upon a time, there was a little girl named Lily. She loved to play with her toys and eat snacks\n",
      "- Tilly had the best day! She woke up in the morning and put on her new pants. They were so big that t\n",
      "- Once upon a time, there were two friends, Jack and Jane. They were playing together in the park with\n",
      "- Mum and Dad were packing for a trip.\n",
      "\n",
      "Mum said to Dad, \"Let's get the egg in the suitcase.\"\n",
      "\n",
      "Dad agr\n",
      "\n",
      "=== AFTER (SAE monosemantic feature) ===\n",
      "- Once upon a time there was a little girl named Jane. She left the house early one morning to go visi\n",
      "- Once there was a little girl who wanted to watch the television. She approached the large television\n",
      "- Once upon a time, there was a foolish little mouse. He was so foolish that he thought he could bite \n",
      "- One day, there was a little girl called Sam who loved to play games. She particularly liked playing \n",
      "- Once upon a time, there was a big pink elephant who had a bright yellow spot on his back. He liked t\n"
     ]
    }
   ],
   "source": [
    "# 11. Demonstrate monosemanticity:\n",
    "# Compare neuron vs SAE-feature before/after.\n",
    "\n",
    "def show_top_sentences(neuron_idx, n=10):\n",
    "    # baseline: original GPT-2 neuron\n",
    "    idxs = torch.topk(all_acts[:, neuron_idx], k=n).indices\n",
    "    return [texts[i % len(texts)] for i in idxs]\n",
    "\n",
    "\n",
    "def show_top_feature(feature_idx, n=10):\n",
    "    with torch.no_grad():\n",
    "        # Use matrix multiplication, not a callable parameter\n",
    "        z = torch.relu(all_acts.to(device) @ sae.W_enc.t()).cpu()\n",
    "    idxs = torch.topk(z[:, feature_idx], k=n).indices\n",
    "    return [texts[i % len(texts)] for i in idxs]\n",
    "\n",
    "\n",
    "neuron = polysemantic_neurons[0]\n",
    "\n",
    "print(\"=== BEFORE (polysemantic neuron) ===\")\n",
    "for s in show_top_sentences(neuron, 5):\n",
    "    print(\"-\", s[:100])\n",
    "\n",
    "print(\"\\n=== AFTER (SAE monosemantic feature) ===\")\n",
    "for s in show_top_feature(0, 5):\n",
    "    print(\"-\", s[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b18425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
